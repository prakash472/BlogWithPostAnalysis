{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras-ReviewAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BZ_th5hr0LB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5af321-b048-4062-adfe-c52b5246f348"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK9shblisEuL",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "fad10407-3cb8-44ed-d565-d99d27744336"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e312d253-cfca-48e3-8eb7-2e596d4deb5d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e312d253-cfca-48e3-8eb7-2e596d4deb5d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"prakash472\",\"key\":\"e09c0084da5ef1992a912c0760649015\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir3nfBdusqFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7662e695-e7ed-4455-db19-0e4dfe644a74"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#change permission\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "#Load the dataset from api\n",
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 66% 17.0M/25.7M [00:00<00:00, 77.3MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 74.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfEVes-t6gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea987a7f-4166-417f-e5ba-b50a6721b1f3"
      },
      "source": [
        "!unzip /content/imdb-dataset-of-50k-movie-reviews.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj37hkX_lsJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c80b41-1b31-45d8-b23a-2867be3dd771"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 26.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 33.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30539 sha256=f21f4afbd87bcdd4b4f407c859027db34298864bda02695524ad7d4c2e51a42a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=79f4c29de0cf957083ff3e2ae169c9f329c7cd3900fbbc0d77ff48f0cdf0803f\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=4c10c69601cbd59d9153088cee83018299a7bcecfd368f11ac8fdd19be011bcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf5mCKUEl_hN"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_hub as hub\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3IyBMUHm4_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa41a68f-de69-4605-e259-2cdd80cf1b81"
      },
      "source": [
        "#reading dataset\n",
        "import pandas as pd\n",
        "movie_reviews=pd.read_csv(\"/content/imdb-dataset-of-50k-movie-reviews.zip\")\n",
        "movie_reviews.isnull().values.any()\n",
        "movie_reviews.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhgSJFurxQxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "64e28c36-ba1e-4a59-f1e0-2489bb1572bd"
      },
      "source": [
        "movie_reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nPbN5s_zWuG"
      },
      "source": [
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwwcZJL5xi0I"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "  \n",
        "  #Removing HTML tags\n",
        "  sentence=remove_tags(sen)\n",
        "\n",
        "  #Select only alphabet characters\n",
        "  sentence=re.sub('[^A-Za-z]',' ',sentence)\n",
        "\n",
        "  #Removing multiple spaces\n",
        "  sentence=re.sub(r\"\\s+\",\" \", sentence)\n",
        "\n",
        "  #Remove the single character\n",
        "  #sentence=re.sub(r\"\\s+[A-Za-z]+\\s+\",' ', sentence)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcE8rrxEylm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953660f7-bc12-44e0-cba6-0ffdb807ccee"
      },
      "source": [
        "print(preprocess_text(\"Ram123 is a boy@123e\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ram is a boy e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAOIx8c500a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c78ba3-be5b-4c99-9ce2-43cd9cdc82e9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnxlyqCZ1F2b"
      },
      "source": [
        "# The above text revies consists of various tags and number so lets clean it\n",
        "reviews=[]\n",
        "sentences=list(movie_reviews[\"review\"])\n",
        "for sentence in sentences:\n",
        "  reviews.append(preprocess_text(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_lsuRkn1PYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cc95fd-dc59-41db-e7ef-edc97818260d"
      },
      "source": [
        "print(movie_reviews.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['review' 'sentiment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04VVoAEY155S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "89acf014-70c0-4c2d-aaa5-166484966d2a"
      },
      "source": [
        "# Here we have sentiment in form of categorical data so we convert it into numbers. Since, only\n",
        "# one can define both positive and negative.\n",
        "sentiment=pd.get_dummies(movie_reviews['sentiment'],drop_first=True)\n",
        "sentiment.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   positive\n",
              "0         1\n",
              "1         1\n",
              "2         1\n",
              "3         0\n",
              "4         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ8ElDI7HXqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0270312f-a632-4589-aa4e-46280a0aef00"
      },
      "source": [
        "# We do not require a dataframe but rather a list so\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "if type(sentiment) != list:\n",
        "  sentiment=list(sentiment[\"positive\"])\n",
        "  print(len(sentiment))\n",
        "  print(sentiment[3])\n",
        "\n",
        "sentiments=[]\n",
        "sentiments_sentences=list(movie_reviews[\"sentiment\"])\n",
        "for sentiment_sentence in sentiments_sentences:\n",
        "  sentiments.append(sentiment_sentence)\n",
        "sentiment=np.array(sentiments)\n",
        "sentiment.shape\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E615SoDn2_UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b32d022-35cc-4ffe-ec2c-351a69299d67"
      },
      "source": [
        "# Here reviews variable contains the reviews and sentiment variable contains the sentiment. \n",
        "# Let's check for 4th review or 3rd index review. From above it is negative one.\n",
        "print(reviews[3]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basically there s a family where a little boy Jake thinks there s a zombie in his closet his parents are fighting all the time This movie is slower than a soap opera and suddenly Jake decides to become Rambo and kill the zombie OK first of all when you re going to make a film you must Decide if its a thriller or a drama As a drama the movie is watchable Parents are divorcing arguing like in real life And then we have Jake with his closet which totally ruins all the film I expected to see a BOOGEYMAN similar movie and instead i watched a drama with some meaningless thriller spots out of just for the well playing parents descent dialogs As for the shots with Jake just ignore them \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbZN37ZG3oAo"
      },
      "source": [
        "\"\"\"\n",
        "Here Bert creates its own tokenizer. Here, we have our data. Now let's create the BERT representation\n",
        "of our text. In order to use BERT word embeddings we need to tokenize our text. In BERT we have\n",
        "[cls]--classification \n",
        "TEXT\n",
        "[SEP]\n",
        "tokens. \n",
        "Since BERT has its own tokenizer we create the bert tokenizer. It can be done as\n",
        "\"\"\"\n",
        "''' \n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
        " '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Qqt6CD-t66"
      },
      "source": [
        "''' tokenizer.tokenize(\"Hey my Name is Prakash. Don't be so judgemental\") '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOriNXXx_MYN"
      },
      "source": [
        "#Here, the tokens have been created. So we can also get their ids of tokens as\n",
        "''' tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"Hey my Name is Prakash. Don't be so judgemental\"))\n",
        " '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBkKt5ZBANJ-"
      },
      "source": [
        "# Now let's tokenize every sentence from our reviews\n",
        "def tokenize_reviews(review):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(review))\n",
        "\n",
        "tokenized_reviews=[tokenize_reviews(review) for review in reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijjUflUZANGL"
      },
      "source": [
        "\"\"\"\n",
        "In the bert model we should have equal input length or the tokens should be of same size. In order\n",
        "to do that we can add the pre padding zeros or post adding zeros. Since our sentence length is \n",
        "too large performing them on a single instance will create a large matrix. Since, we will be \n",
        "training in batches we can adjust the tokens according to batches. Now, Let's create our final\n",
        "data which consists of review, length of review and sentiment of that review. We have list of \n",
        "list.[[review_1,length_1,sentiment_1],\n",
        "      [review_2,length_2,sentiment_2],\n",
        "]\n",
        "\"\"\"\n",
        "reviews_with_len=[[review, len(review),sentiment[i]] for i,review in enumerate(tokenized_reviews)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL1LI9V0K4Q2"
      },
      "source": [
        "''' import random\n",
        "#Just shuffling the data\n",
        "random.shuffle(reviews_with_len) '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3wBW5L-LJ2F"
      },
      "source": [
        "# Here, we have inputs but lets sort them according to their length so that padding of \n",
        "# tokens becomes easy when we work with batches. So, it is useful from preventing creation of sparse matrix and fast processing.\n",
        "# The lambda function sorts with entry according to length of the reviews\n",
        "#reviews_with_len.sort(key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMdFXlsCL1E5"
      },
      "source": [
        "# Once the data are sorted according to the length of the reviews there is no further need to store the length. We can remove it\n",
        "#sorted_reviews=[(review[0],review[2]) for review in reviews_with_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w25IrB9LV5lR"
      },
      "source": [
        "# Lets convert it into tf format\n",
        "#processed_dataset=tf.data.Dataset.from_generator(lambda: sorted_reviews, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDVH50h1Wfgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8330bb28-1821-4e82-88f1-9c883c4f1460"
      },
      "source": [
        "#type(processed_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.FlatMapDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a3NhHIlgJAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418573c2-20ba-469d-ddda-34bcd8db6c66"
      },
      "source": [
        "''' BATCH_SIZE=32\n",
        "batched_dataset=processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ),()))\n",
        "next(iter(batched_dataset)) '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 22), dtype=int32, numpy=\n",
              " array([[ 3078,  5436,  3078,  3257,  3532,  7613,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 3191,  1996,  2338,  5293,  1996,  3185,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2062, 23873,  3993,  2062, 11259,  2172,  2172,  2062, 14888,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2054,  1037,  5896,  2054,  1037,  2466,  2054,  1037,  6752,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2023,  3185,  2003,  6659,  2021,  2009,  2038,  2070,  2204,\n",
              "          3896,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 8235,  1998,  3048,  4616,  2011,  3419,  2457, 27727,  1998,\n",
              "          2848, 16133,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 1045,  2876,  1056,  9278,  2023,  2028,  2130,  2006,  7922,\n",
              "         12635,  2305,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 1045,  3246,  2023,  2177,  1997,  2143, 11153,  2196,  2128,\n",
              "         15908,  2015,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 7918, 14674,  7662,  2003,  6581,  2003,  2023,  2143,  2002,\n",
              "          3084,  1037, 17160,  2450,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2023,  2003,  1037,  2307,  3185,  2205,  2919,  2009,  2003,\n",
              "          2025,  2800,  2006,  2188,  2678,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [11861,  1996, 21442,  6895,  3238,  2515,  1037,  2210, 22759,\n",
              "          6198,  1998,  1037,  3185,  2087, 12487,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2053,  7615,  5236,  3185,  3772,  2779,  2030,  4788,  9000,\n",
              "          2053,  3168,  2012,  2035, 13558,  2009,     0,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2017,  1040,  2488,  5454,  2703,  2310, 25032,  8913,  8159,\n",
              "          1055,  2130,  2065,  2017,  2031,  3427,  2009,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2074,  2293,  1996,  6970, 13068,  2090,  2048,  2307,  3494,\n",
              "          1997,  2754,  3898,  2310,  3593,  2102,  6287,  5974,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2023,  2003,  1996, 15764,  3185,  2544,  1997,  8429, 24905,\n",
              "         17988,  7659,  2498,  2021,  2045,  2024,  2053, 13842,  5312,\n",
              "             0,     0,     0,     0],\n",
              "        [ 5587,  2023,  2210, 17070,  2000,  2115,  2862,  1997,  6209,\n",
              "         24945,  2009, 26354, 28394,  2102,  6057,  1998,  2203, 27242,\n",
              "             0,     0,     0,     0],\n",
              "        [ 7615,  2023,  3185,  2003,  5263,  2003,  6659,  2200, 17727,\n",
              "          3217,  3676,  3468,  2919,  7613,  1041,  3257,  2025,  2298,\n",
              "             0,     0,     0,     0],\n",
              "        [ 2146, 11771,  1038,  8523,  8458,  6633,  3560,  2196,  2031,\n",
              "          1045,  2042,  2061,  5580,  2000,  2156,  4566,  6495,  4897,\n",
              "             0,     0,     0,     0],\n",
              "        [ 1037,  5790,  1997,  2515,  2025,  4088,  2000,  4671,  2129,\n",
              "         10634,  2139, 24128,  1998, 21660,  2135,  2919,  2023,  3185,\n",
              "          2003,     0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  1055,  2026,  5440,  2792,  1997,  2235,\n",
              "          3077,     0,     0,     0],\n",
              "        [ 6283,  2009,  2007,  2035,  2026,  2108,  5409,  3185,  2412,\n",
              "         10597, 21985,  2393,  2033,  2009,  2001,  2008,  2919,  3404,\n",
              "          2033,     0,     0,     0],\n",
              "        [ 1045,  2123,  1056,  2113,  2339,  1045,  2066,  2023,  3185,\n",
              "          2061,  2092,  2021,  1045,  2196,  2131,  5458,  1997,  3666,\n",
              "          2009,     0,     0,     0],\n",
              "        [ 2023,  2003,  1037,  2204,  2143,  2023,  2003,  2200,  6057,\n",
              "          2664,  2044,  2023,  2143,  2045,  2020,  2053,  2204,  8471,\n",
              "          3152,     0,     0,     0],\n",
              "        [ 1037,  2033,  6491, 11124,  6774,  2143,  2008,  5121,  7906,\n",
              "          2115,  3086,  3841, 13196,  2003, 17160,  1998, 26103,  2000,\n",
              "          3422,     0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  1055,  2026,  5440,  2792,  1997,  2235,\n",
              "          3077,     0,     0,     0],\n",
              "        [ 7078, 10392,  3649,  1045,  2360,  2876,  1056,  2079,  2023,\n",
              "          2104,  9250,  3185,  1996,  3425,  2009, 17210,  3422,  2009,\n",
              "          2085, 10392,     0,     0],\n",
              "        [ 1037,  7244,  3185,  2009,  2003,  2440,  1997,  6699,  1998,\n",
              "          6919,  3772,  1045,  2071,  2031,  2938,  2083,  2009,  1037,\n",
              "          2117,  2051,     0,     0],\n",
              "        [ 2005,  5760,  7788,  4393,  8808,  2498,  2064, 12826,  2000,\n",
              "          1996, 11056,  3152,  1045,  3811, 16755,  2169,  1998,  2296,\n",
              "          2028,  1997,  2068,     0],\n",
              "        [ 2307,  3185,  2926,  1996,  2189,  3802,  2696,  2508,  2012,\n",
              "          2197,  2023,  8847,  6702,  2043,  2017,  2031,  2633,  2179,\n",
              "          2008,  2569,  2619,     0],\n",
              "        [ 2023,  3185,  2097,  2467,  2022,  1037,  5934,  1998,  3185,\n",
              "          4438,  2004,  2146,  2004,  2045,  2024,  2145,  2111,  2040,\n",
              "          6170,  3153,  1998,  2552],\n",
              "        [ 2028,  1997,  1996,  4569, 15580,  2102,  5691,  2081,  1999,\n",
              "          3522,  2086,  2204, 23191,  5436,  1998, 11813,  6370,  2191,\n",
              "          2023,  2028,  1037,  4438],\n",
              "        [ 6581,  2792,  3185, 21862, 16016,  4349,  2420,  5920,  2015,\n",
              "          2009,  2987,  2102,  2131,  2062,  2139, 24128,  2084,  2023,\n",
              "          3185,  5790,  2189,  5790]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IotUXYMog80B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a2a0a1-844d-4a1e-b7b1-9319800fa500"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-18 02:14:52--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.240, 172.217.13.80, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   164MB/s    in 2.4s    \n",
            "\n",
            "2020-11-18 02:14:54 (164 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4fCpZRKFFNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f74822e-d268-496e-a018-131c784c2c34"
      },
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-L5WmY0GYj1"
      },
      "source": [
        "import os\n",
        "os.makedirs(\"model\",exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nbZPASGuhE"
      },
      "source": [
        "!mv uncased_L-12_H-768_A-12/ model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yml9oNZHGh6"
      },
      "source": [
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "bert_ckpt_dir=os.path.join(\"/content/model\",bert_model_name)\n",
        "bert_ckpt_file=os.path.join(bert_ckpt_dir,\"bert_model.ckpt\")\n",
        "bert_config_file=os.path.join(bert_ckpt_dir,\"bert_config.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsZiZCl-IwwJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf046676-3e92-44ba-f182-ef022c5c24f8"
      },
      "source": [
        "bert_ckpt_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/model/uncased_L-12_H-768_A-12/bert_model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3CGjQqzI6sl"
      },
      "source": [
        "tokenizer=bert.bert_tokenization.FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir,\"vocab.txt\"),do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBYqK2LRLO45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85e87ab-ce03-480e-ca07-b921d3be5d68"
      },
      "source": [
        "tokens=tokenizer.tokenize(\"I am leaving here. Can't go out from here!\")\n",
        "print(len(tokens))\n",
        "tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1045, 2572, 2975, 2182, 1012, 2064, 1005, 1056, 2175, 2041, 2013, 2182, 999]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv2FcDVRMGUt"
      },
      "source": [
        "# Now let's tokenize every sentence from our reviews\n",
        "MAX_LENGTH=256\n",
        "def tokenize_reviews(reviews):\n",
        "  tokenized_reviews=[]\n",
        "  for review in reviews:\n",
        "    tokens=tokenizer.tokenize(review)\n",
        "    if len(tokens)>MAX_LENGTH-2:\n",
        "      tokens=tokens[:MAX_LENGTH-2]\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    token_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    tokenized_reviews.append(token_ids)\n",
        "  return tokenized_reviews\n",
        "tokenized_reviews=tokenize_reviews(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXfqWn0jNkY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99984f5a-0692-4f65-a216-0eca6eba3445"
      },
      "source": [
        "print(tokenized_reviews[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1045, 2245, 2023, 2001, 1037, 6919, 2126, 2000, 5247, 2051, 2006, 1037, 2205, 2980, 2621, 5353, 3564, 1999, 1996, 2250, 22442, 4258, 1998, 3666, 1037, 2422, 18627, 4038, 1996, 5436, 2003, 21934, 24759, 6553, 2021, 1996, 7982, 2003, 25591, 1998, 1996, 3494, 2024, 5622, 2912, 3468, 2130, 1996, 2092, 7852, 6878, 7642, 6359, 2096, 2070, 2089, 2022, 9364, 2043, 2027, 5382, 2023, 2003, 2025, 2674, 2391, 3891, 13449, 1045, 2245, 2009, 2001, 6947, 2008, 13703, 5297, 2003, 2145, 3929, 1999, 2491, 1997, 1996, 2806, 2116, 1997, 2149, 2031, 4961, 2000, 2293, 2023, 2001, 1996, 2087, 1045, 1040, 4191, 2012, 2028, 1997, 13703, 1055, 22092, 1999, 2086, 8108, 1045, 2360, 1037, 5476, 2096, 1045, 2310, 2196, 2042, 7622, 2007, 11862, 13093, 3385, 1999, 2023, 2016, 3266, 2000, 4309, 2091, 2014, 7916, 3746, 1998, 5598, 2157, 2046, 1037, 2779, 2021, 24462, 2402, 2450, 2023, 2089, 2025, 2022, 1996, 4410, 13713, 1997, 2010, 2476, 2021, 2009, 2001, 15966, 17579, 2084, 6548, 11651, 10975, 8447, 1998, 2062, 5875, 2084, 10646, 1037, 2307, 4038, 2000, 2175, 2156, 2007, 2814, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw9qBHdxTzdK"
      },
      "source": [
        "Since the length of the tokens is very large we simply truncate it to the 256 bits. We use Keras helper function to pad the sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMFO9kSkZgOD"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tokens_with_paading=pad_sequences(tokenized_reviews,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\",value=0)\n",
        "tokens_with_paading[700]\n",
        "tokens_with_paading=np.array(tokens_with_paading)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSsdIXWCs9Dz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs,test_inputs,train_labels,test_labels=train_test_split(tokens_with_paading,sentiment, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geue1G_y2Hxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415d30e5-e0a5-4d67-b605-8a2e2a720b7d"
      },
      "source": [
        "train_inputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42500, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ml2XmlcudRS"
      },
      "source": [
        "def create_model(max_seq_len, bert_ckpt_file):\n",
        "\n",
        "  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "      stock_params = StockBertConfig.from_json_string(reader.read())\n",
        "      bert_params  = stock_params.to_bert_model_layer_params()\n",
        "      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "        \n",
        "  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "  bert_output = bert(input_ids)\n",
        "\n",
        "  print(\"bert shape\", bert_output.shape)\n",
        "\n",
        "  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "  cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "  logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "  logits = keras.layers.Dropout(0.5)(logits)\n",
        "  logits = keras.layers.Dense(units=1, activation=\"sigmoid\")(logits)\n",
        "\n",
        "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "        \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGla0Rekv9Oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e604916-841f-4caa-afb9-bc07ab1d975c"
      },
      "source": [
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, load_stock_weights\n",
        "model = create_model(MAX_LENGTH, bert_ckpt_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert shape (None, 256, 768)\n",
            "Done loading 196 BERT weights from: /content/model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7f53dc0b5da0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNz0TGC-0Mln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1566c551-58ad-4f77-e36a-42a4451a593e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "bert (BertModelLayer)        (None, 256, 768)          108890112 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 769       \n",
            "=================================================================\n",
            "Total params: 109,481,473\n",
            "Trainable params: 109,481,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5WSmu-U0hnY"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(1e-5),\n",
        "  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "  metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl-ChJU11fou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a26a87-ec35-4ded-fe02-d4daae4fbddc"
      },
      "source": [
        "import datetime\n",
        "log_dir = \"log/intent_detection/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "history = model.fit(\n",
        "  x=train_inputs, \n",
        "  y=train_labels,\n",
        "  validation_split=0.15,\n",
        "  batch_size=16,\n",
        "  shuffle=True,\n",
        "  epochs=5,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2258/2258 [==============================] - 2695s 1s/step - loss: 0.5715 - accuracy: 0.8444 - val_loss: 0.5489 - val_accuracy: 0.9043\n",
            "Epoch 2/5\n",
            "2258/2258 [==============================] - 2703s 1s/step - loss: 0.5470 - accuracy: 0.9050 - val_loss: 0.5703 - val_accuracy: 0.8257\n",
            "Epoch 3/5\n",
            "2258/2258 [==============================] - 2696s 1s/step - loss: 0.5432 - accuracy: 0.9140 - val_loss: 0.5616 - val_accuracy: 0.8955\n",
            "Epoch 4/5\n",
            "2258/2258 [==============================] - 2693s 1s/step - loss: 0.5402 - accuracy: 0.9195 - val_loss: 0.5441 - val_accuracy: 0.9153\n",
            "Epoch 5/5\n",
            "2258/2258 [==============================] - 2676s 1s/step - loss: 0.5380 - accuracy: 0.9233 - val_loss: 0.5452 - val_accuracy: 0.9035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCR3juXXwq2H"
      },
      "source": [
        "model.save_weights(\"sentiment_bert_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "3bRSorerJkPA",
        "outputId": "009d92a8-614b-4f90-ce8a-eeb513792026"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3794de7b-5d91-4b31-b0e1-36f939789134\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3794de7b-5d91-4b31-b0e1-36f939789134\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sentiment_bert_weights.h5 to sentiment_bert_weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SBAqJbB8NNa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "ae5fa792-aabd-4b2c-8a78-d3a29f323dcf"
      },
      "source": [
        "model.load_weights(\"sentiment_bert_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2f638b99f2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment_bert_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWl__6bHyCyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec51fe6f-7fff-49ae-a730-a22e8d9dd43d"
      },
      "source": [
        "_, train_acc = model.evaluate(train_inputs, train_labels)\n",
        "_, test_acc = model.evaluate(test_inputs, test_labels)\n",
        "\n",
        "print(\"train acc\", train_acc)\n",
        "print(\"test acc\", test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1329/1329 [==============================] - 826s 622ms/step - loss: 0.5327 - accuracy: 0.9324\n",
            "235/235 [==============================] - 147s 624ms/step - loss: 0.5448 - accuracy: 0.9035\n",
            "train acc 0.9323999881744385\n",
            "test acc 0.9034666419029236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-fo3Dgc3EOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2296e84-f221-4c26-da20-d3a67b0b62dc"
      },
      "source": [
        "list_test=[]\n",
        "raw_text_2=\"Hey my_name is prakash. I am not just doing a NLP intro.\"\n",
        "preprocess_raw_text=preprocess_text(raw_text_2)\n",
        "print(preprocess_raw_text)\n",
        "list_test.append(preprocess_raw_text)\n",
        "print(list_test)\n",
        "tokenize_raw_text=tokenize_reviews(list_test)\n",
        "print(tokenize_raw_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hey my name is prakash I am not just doing a NLP intro \n",
            "['Hey my name is prakash I am not just doing a NLP intro ']\n",
            "[[101, 4931, 2026, 2171, 2003, 22233, 1045, 2572, 2025, 2074, 2725, 1037, 17953, 2361, 17174, 102]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MkN9e723Eat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f7b31f-8b0c-4423-930c-5e664a4c4987"
      },
      "source": [
        "test_input_with_padding=pad_sequences(tokenize_raw_text,maxlen=MAX_LENGTH,padding=\"post\",truncating=\"post\",value=0)\n",
        "test_input_with_padding=np.array(test_input_with_padding)\n",
        "test_input_with_padding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyPtBfba3EhX",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa136a52-5964-48a0-ef99-4bc2b2a59f9b"
      },
      "source": [
        "prediction=model.predict(test_input_with_padding)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdwJ-4X93Eeq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6H-H-5d1gAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e85fe87-5952-4b72-88b6-3f7593c589f3"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C6urTk6coIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab169489-146f-4dd4-bebe-cf318c404797"
      },
      "source": [
        "test_str=\"In the United Kingdom, periodicals like The Strand Magazine and Story-Teller contributed to the popularity of the short story. Hector Hugh Munro (1870–1916), also known by his pen name of Saki, wrote satirical short stories about Edwardian England. W. Somerset Maugham, who wrote over a hundred short stories, was one of the most popular authors of his time. P.G. Wodehouse published his first collection of comical stories about valet Jeeves in 1917. Many detective stories were written by G.K. Chesterton, Agatha Christie and Dorothy L. Sayers. Short stories by Virginia Woolf are Kew Gardens (1919) and Solid Objects, about a politician with mental problems. Graham Greene wrote his Twenty-One Stories between 1929 and 1954. A specialist in the short story was V.S. Pritchett, whose first collection appeared in 1932. Arthur C. Clarke published his first science fiction story, Travel by Wire in 1937. Evelyn Waugh, Muriel Spark and L.P. Hartley were other popular British storytellers whose career started in this period.\"\n",
        "print(len(test_str))\n",
        "tokens=tokenizer.tokenize(test_str)\n",
        "print(tokens)\n",
        "print(len(tokens))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1025\n",
            "['in', 'the', 'united', 'kingdom', ',', 'periodicals', 'like', 'the', 'strand', 'magazine', 'and', 'story', '-', 'teller', 'contributed', 'to', 'the', 'popularity', 'of', 'the', 'short', 'story', '.', 'hector', 'hugh', 'munro', '(', '1870', '–', '1916', ')', ',', 'also', 'known', 'by', 'his', 'pen', 'name', 'of', 'sa', '##ki', ',', 'wrote', 'satirical', 'short', 'stories', 'about', 'edward', '##ian', 'england', '.', 'w', '.', 'somerset', 'ma', '##ugh', '##am', ',', 'who', 'wrote', 'over', 'a', 'hundred', 'short', 'stories', ',', 'was', 'one', 'of', 'the', 'most', 'popular', 'authors', 'of', 'his', 'time', '.', 'p', '.', 'g', '.', 'wo', '##deh', '##ouse', 'published', 'his', 'first', 'collection', 'of', 'comical', 'stories', 'about', 'valet', 'je', '##eves', 'in', '1917', '.', 'many', 'detective', 'stories', 'were', 'written', 'by', 'g', '.', 'k', '.', 'chester', '##ton', ',', 'agatha', 'christie', 'and', 'dorothy', 'l', '.', 'say', '##ers', '.', 'short', 'stories', 'by', 'virginia', 'woolf', 'are', 'ke', '##w', 'gardens', '(', '1919', ')', 'and', 'solid', 'objects', ',', 'about', 'a', 'politician', 'with', 'mental', 'problems', '.', 'graham', 'greene', 'wrote', 'his', 'twenty', '-', 'one', 'stories', 'between', '1929', 'and', '1954', '.', 'a', 'specialist', 'in', 'the', 'short', 'story', 'was', 'v', '.', 's', '.', 'pri', '##tch', '##ett', ',', 'whose', 'first', 'collection', 'appeared', 'in', '1932', '.', 'arthur', 'c', '.', 'clarke', 'published', 'his', 'first', 'science', 'fiction', 'story', ',', 'travel', 'by', 'wire', 'in', '1937', '.', 'evelyn', 'wa', '##ugh', ',', 'muriel', 'spark', 'and', 'l', '.', 'p', '.', 'hartley', 'were', 'other', 'popular', 'british', 'story', '##tell', '##ers', 'whose', 'career', 'started', 'in', 'this', 'period', '.']\n",
            "221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht4NOb5Lhpzt"
      },
      "source": [
        "raw_text_1=\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
        "raw_text_2=\"Hey my_name is prakash. I am not just doing a NLP intro.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnC1tV21hp_c"
      },
      "source": [
        "process_text_1=preprocess_text(raw_text_1)\n",
        "process_text_2=preprocess_text(raw_text_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setDupuVhqFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8995a032-3437-4755-9dfc-3415b05945ec"
      },
      "source": [
        "test_tokens=[]\n",
        "tokens_1=list(tokenizer.tokenize(process_text_1))\n",
        "tokens_2=list(tokenizer.tokenize(process_text_2))\n",
        "print(tokens_1)\n",
        "print(tokens_2)\n",
        "test_tokens.append(tokens_1)\n",
        "test_tokens.append(tokens_2)\n",
        "print(len(test_tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'un', '##fl', '##in', '##ching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'tim', '##id', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'pen', '##ite', '##nta', '##ry', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inward', '##s', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryan', '##s', 'muslims', 'gangs', '##tas', 'latino', '##s', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'sc', '##uf', '##fles', 'death', 'stares', 'dod', '##gy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'doesn', 't', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'manner', '##ed', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitch', '##es', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'that', '##s', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n",
            "['hey', 'my', 'name', 'is', 'prakash', 'i', 'am', 'not', 'just', 'doing', 'a', 'nl', '##p', 'intro']\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PwmEx6hqCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeda28bc-345c-4589-d93e-bd4432db035a"
      },
      "source": [
        "print(len(tokens_1))\n",
        "print(len(tokens_2))\n",
        "print(len(test_tokens))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "330\n",
            "14\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DllUvXfylRhA"
      },
      "source": [
        "for test_token in test_tokens:\n",
        "  if len(test_token)>254:\n",
        "    test_token=test_token[:254]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suM0z5ZmmUOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecff01a4-e101-4739-9f8d-14f6ea4e4c14"
      },
      "source": [
        "len(test_tokens[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    }
  ]
}